{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "[[8, 0, 8, 7, 0, 8, 6, 1, 4, 4, 22, 2, 0, 0, 8], [9, 0, 3, 0, 0, 7, 6, 1, 9, 5, 12, 3, 0, 0, 8], [3, 10, 0, 1, 5, 1, 2, 4, 0, 1, 0, 0, 5, 6, 1], [0, 10, 0, 0, 8, 1, 0, 9, 0, 1, 0, 0, 5, 7, 1]]\n",
      "[[2, 0, 4, 1, 0, 7, 4, 1, 8, 0, 11, 7, 0, 0, 4], [0, 4, 0, 0, 4, 1, 0, 3, 0, 1, 0, 0, 7, 2, 0]]\n",
      "2\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "# dic = {}\n",
    "# doc = []\n",
    "# with open('not_spam','r') as infile:\n",
    "#     for line in infile:\n",
    "#         doc.append(line.split())\n",
    "#         for word in line.split():\n",
    "#             if word in dic:\n",
    "#                 dic[word] += 1\n",
    "#             else:\n",
    "#                 dic[word] = 1\n",
    "\n",
    "# # for key in dic.keys():\n",
    "# with open('not_spam','r') as infile:\n",
    "#     for line in infile:\n",
    "#         for key in dic.keys():\n",
    "#             if key in line:\n",
    "#                 d[key] = line.count(key)\n",
    "                \n",
    "# # document\n",
    "# print(dic)\n",
    "# for i in range(len(doc)):\n",
    "#     for key,value in dic.items():\n",
    "#         if key in doc[i]:\n",
    "d1 = {'subscribe':10, 'notify':5,'account':7, 'unsubscribe':9,'receive':8,'Saheed':0, 'Busari': 1, 'is': 1, 'father' :0, 'Olaide' :1, 'Emmanuel' :0, 'Oni' : 0, 'Banwo' : 0, 'Toni' :0, 'Banji':0}\n",
    "d2 = {'subscribe':4, 'notify':7,'account':2, 'unsubscribe':3,'receive':4,'Saheed':0, 'Busari': 0, 'is': 1, 'father' :0, 'Olaide' :1, 'Emmanuel' :0, 'Oni' : 0, 'Banwo' : 0, 'Toni' :0, 'Banji':0}\n",
    "d3 = {'subscribe':10, 'notify':5,'account':6, 'unsubscribe':4,'receive':5,'Saheed':0, 'Busari': 1, 'is': 1, 'father' :3, 'Olaide' :1, 'Emmanuel' :0, 'Oni' : 2, 'Banwo' : 0, 'Toni' :0, 'Banji':1}\n",
    "d4 = {'subscribe':0, 'notify':0,'account':0, 'unsubscribe':1,'receive':0,'Saheed':3, 'Busari': 8, 'is': 7, 'father' :9, 'Olaide' :5, 'Emmanuel' :3, 'Oni' : 6, 'Banwo' : 12, 'Toni' :9, 'Banji':0}\n",
    "d5 = {'subscribe':0, 'notify':0,'account':0, 'unsubscribe':1,'receive':0,'Saheed':8, 'Busari': 8, 'is': 8, 'father' :8, 'Olaide' :4, 'Emmanuel' :2, 'Oni' : 6, 'Banwo' : 22, 'Toni' :4, 'Banji':7}\n",
    "d6 = {'subscribe':0, 'notify':0,'account':0, 'unsubscribe':1,'receive':0,'Saheed':4, 'Busari': 4, 'is': 7, 'father' :2, 'Olaide' :0, 'Emmanuel' :7, 'Oni' : 4, 'Banwo' : 11, 'Toni' :8, 'Banji':1}\n",
    "\n",
    "no_spam_dic_doc = {'d1':d1,'d2':d2,'d3':d3}\n",
    "spam_dic_doc = {'d4':d4,'d5':d5,'d6':d6}\n",
    "# d_label = {'d1':0,'d2':0,'d3':0,'d4':1,'d5':1,'d6':1}\n",
    "n_neighbors = 2\n",
    "\n",
    "# spam_dict = {'spam_doc1' : {'Saheed':1, 'Busari': 2, 'is': 1, 'father' :1, 'Olaide' :1, 'Emmanuel' :2, \\\n",
    "#                                'Oni' : 3, 'Banwo': 0, 'Toni' :0, 'Banji':0}\n",
    "#              'spam_doc2' : {'Saheed' :0, 'Busari'= 0, 'is'= 0, 'father' =0, 'Olaide' =0, 'Emmanuel' =2, \\\n",
    "#                       'Oni' = 0, 'Banwo' = 5, 'Toni' =0, 'Banji':0) \n",
    "#             }\n",
    "\n",
    "# non_spam_dict = {'non_spam_doc1' : dict ('Saheed' =1, 'Busari'= 2, 'is'= 1, 'father' =1, 'Olaide' =1, 'Emmanuel' =2, \\\n",
    "#                                'Oni' = 3, 'Banwo' = 0, 'Toni' =0, 'Banji'=0 )\n",
    "#              'non_spam_doc2' : dict ('Saheed' =0, 'Busari'= 0, 'is'= 0, 'father' =0, 'Olaide' =0, 'Emmanuel' =2, \\\n",
    "#                       'Oni' = 0, 'Banwo' = 5, 'Toni' =0, 'Banji'=0) \n",
    "#             }\n",
    "\n",
    "def ConvertDictToVect(spam_dict, non_spam_dict):\n",
    "    # Process dictionary\n",
    "    spam_length = len(spam_dict)\n",
    "    non_spam_length = len(non_spam_dict)\n",
    "    test_size = int(spam_length/2)\n",
    "    non_spam_test_size = int(non_spam_length / 2)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    spam_doc_names= list(spam_dict.keys())\n",
    "    non_spam_doc_names = list(non_spam_dict.keys())\n",
    "    for i in range(spam_length): \n",
    "        doc_dict = spam_dict[spam_doc_names[i]]\n",
    "        if i < test_size:\n",
    "            y_test.append(1)\n",
    "            X_test.append(list(doc_dict.values()))\n",
    "        else:\n",
    "            X_train.append(list(doc_dict.values()))\n",
    "            y_train.append(1)\n",
    "    \n",
    "    for i in range(non_spam_length):\n",
    "        doc_dict = non_spam_dict[non_spam_doc_names[i]]\n",
    "        if i < non_spam_test_size:\n",
    "            y_test.append(0)\n",
    "            X_test.append(list(doc_dict.values()))\n",
    "        else:\n",
    "            X_train.append(list(doc_dict.values()))\n",
    "            y_train.append(0)\n",
    "            \n",
    "  \n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "    \n",
    "\n",
    "def TrainAndPredict(spam_dict, non_spam_dict):\n",
    "\n",
    "    # GEt train and test\n",
    "    X_train, y_train, X_test, y_test =  ConvertDictToVect(spam_dict, non_spam_dict)\n",
    "    print (X_train)\n",
    "    print (X_test)\n",
    "    print (len(y_test))\n",
    "    for weights in ['uniform', 'distance']:\n",
    "        # we create an instance of Neighbours Classifier and fit the data.\n",
    "        clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "#         clf.predict(X_test)\n",
    "        return clf.score(X_test,y_test)\n",
    "    \n",
    "\n",
    "print(TrainAndPredict(spam_dic_doc, no_spam_dic_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119901\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "spam_folder_path = \"spam\"\n",
    "easy_ham_folder_path = \"easy_ham\"\n",
    "spam_email_list = os.listdir(spam_folder_path)\n",
    "easy_ham_email_list = os.listdir(easy_ham_folder_path)\n",
    "filename = open('stop_words.txt', 'r')\n",
    "stopwords = set()\n",
    "for word in filename: \n",
    "    stopwords.add(word.strip().lower())\n",
    "        \n",
    "# print(stopwords)\n",
    "\n",
    "def GetDictionaryAndCountForEmails(email_list, folder_path):\n",
    "    words = {}\n",
    "    for email in email_list:\n",
    "        email_doc = open(folder_path + '/'+ email, 'r', encoding= 'UTF-8',  errors=\"surrogateescape\")\n",
    "        for line in email_doc:\n",
    "            for word in line.strip().split():\n",
    "                word = word.lower()\n",
    "                if ((word in stopwords) == 1) or ('<' in word):\n",
    "                    continue\n",
    "                if word not in words:\n",
    "                    words[word] = 1\n",
    "                else:\n",
    "                    words[word] = words[word] + 1\n",
    "    return words\n",
    "\n",
    "def GetNewEmptyDictionary(words):\n",
    "    dictionary_list = words.keys()\n",
    "    dictionary = {}\n",
    "    for word in dictionary_list:\n",
    "        dictionary[word] = 0\n",
    "    return dictionary\n",
    "\n",
    "def GetUniqueDictionary(email_list, folder_path):\n",
    "    dictionary_ = {}\n",
    "    for email in email_list:\n",
    "        email_doc = open(folder_path + '/'+ email, 'r', encoding= 'UTF-8',  errors=\"surrogateescape\")\n",
    "        dictionary_[email] = GetNewEmptyDictionary(words)\n",
    "        for line in email_doc:\n",
    "            for word in line.strip().split():\n",
    "                word = word.lower()\n",
    "                if ((word in stopwords) == 1) or ('<' in word):\n",
    "                    continue\n",
    "                dictionary_[email][word] += 1\n",
    "    return dictionary_\n",
    "\n",
    "def ConvertDictToVect(spam_dict, non_spam_dict):\n",
    "    # Process dictionary\n",
    "    spam_length = len(spam_dict)\n",
    "    non_spam_length = len(non_spam_dict)\n",
    "    test_size = int(spam_length/2)\n",
    "    non_spam_test_size = int(non_spam_length / 2)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    spam_doc_names= list(spam_dict.keys())\n",
    "    non_spam_doc_names = list(non_spam_dict.keys())\n",
    "    for i in range(spam_length): \n",
    "        doc_dict = spam_dict[spam_doc_names[i]]\n",
    "        if i < test_size:\n",
    "            y_test.append(1)\n",
    "            X_test.append(list(doc_dict.values()))\n",
    "        else:\n",
    "            X_train.append(list(doc_dict.values()))\n",
    "            y_train.append(1)\n",
    "    \n",
    "    for i in range(non_spam_length):\n",
    "        doc_dict = non_spam_dict[non_spam_doc_names[i]]\n",
    "        if i < non_spam_test_size:\n",
    "            y_test.append(0)\n",
    "            X_test.append(list(doc_dict.values()))\n",
    "        else:\n",
    "            X_train.append(list(doc_dict.values()))\n",
    "            y_train.append(0)\n",
    "            \n",
    "  \n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "    \n",
    "\n",
    "def TrainAndPredict(spam_dict, non_spam_dict):\n",
    "\n",
    "    # GEt train and test\n",
    "    X_train, y_train, X_test, y_test =  ConvertDictToVect(spam_dict, non_spam_dict)\n",
    "    print (X_train)\n",
    "    print (X_test)\n",
    "    print (len(y_test))\n",
    "    for weights in ['uniform', 'distance']:\n",
    "        # we create an instance of Neighbours Classifier and fit the data.\n",
    "        clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "#         clf.predict(X_test)\n",
    "        return clf.score(X_test,y_test)\n",
    "\n",
    "words = GetDictionaryAndCountForEmails(spam_email_list, spam_folder_path)\n",
    "words.update( GetDictionaryAndCountForEmails(easy_ham_email_list, easy_ham_folder_path))\n",
    "print(len(words))\n",
    "dictionary_spam = GetUniqueDictionary(spam_email_list, spam_folder_path)\n",
    "dictionary_nspam = GetUniqueDictionary(easy_ham_email_list, easy_ham_folder_path)\n",
    "\n",
    "print(TrainAndPredict(dictionary_spam, dictionary_nspam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
